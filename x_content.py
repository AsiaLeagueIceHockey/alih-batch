"""
X(Twitter) ì¼ë³¸ì–´ ì»¨í…ì¸  ìƒì„± ìŠ¤í¬ë¦½íŠ¸ - ìŠ¤ë ˆë“œ í˜•ì‹

GitHub Actionsì—ì„œ ì‹¤í–‰ë˜ì–´:
1. Series Review (ì¼ìš”ì¼): ì§€ë‚œ ì£¼ ê²½ê¸° ê²°ê³¼ ìš”ì•½
2. Series Preview (ëª©ìš”ì¼): ë‹¤ìŒ ì£¼ ê²½ê¸° ì˜ˆê³ 
3. Slackìœ¼ë¡œ ìŠ¤ë ˆë“œ í˜•ì‹ í…ìŠ¤íŠ¸ ì „ì†¡ (ë³µì‚¬í•˜ì—¬ Xì— ê²Œì‹œ)

X ê¸€ììˆ˜ ì œí•œ(280ì) ëŒ€ì‘:
- ì²« íŠ¸ìœ—: ìš”ì•½ + í•´ì‹œíƒœê·¸
- í›„ì† íŠ¸ìœ—: ê°œë³„ ê²½ê¸° ì •ë³´ (ë¦¬í”Œë¼ì´)
"""

import os
import sys
import re
from datetime import datetime, timedelta
from supabase import create_client, Client
from groq import Groq
import requests

# --- í™˜ê²½ë³€ìˆ˜ ---
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")

# X ê¸€ììˆ˜ ì œí•œ
X_CHAR_LIMIT = 280

# --- Supabase í´ë¼ì´ì–¸íŠ¸ ---
supabase: Client = None

def init_supabase():
    global supabase
    if not SUPABASE_URL or not SUPABASE_KEY:
        raise EnvironmentError("SUPABASE_URL and SUPABASE_SERVICE_KEY must be set.")
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)


# =============================================================================
# 1. Supabase ë°ì´í„° ì¡°íšŒ
# =============================================================================

def get_team_info() -> dict:
    """alih_teamsì—ì„œ íŒ€ ì •ë³´ ì¡°íšŒ (ì¼ë³¸ì–´ ì´ë¦„ í¬í•¨)"""
    response = supabase.table('alih_teams') \
        .select('id, name, english_name, japanese_name') \
        .execute()
    return {team['id']: team for team in response.data}


def get_standings_info() -> dict:
    """alih_standingsì—ì„œ ìˆœìœ„ ì •ë³´ ì¡°íšŒ"""
    response = supabase.table('alih_standings') \
        .select('team_id, rank, points, games_played') \
        .order('rank') \
        .execute()
    return {s['team_id']: s for s in response.data}


def get_weekly_results() -> list:
    """ì§€ë‚œ 7ì¼ê°„ ì™„ë£Œëœ ê²½ê¸° ì¡°íšŒ (Reviewìš©)"""
    now_kst = datetime.utcnow() + timedelta(hours=9)
    today_end = now_kst.replace(hour=23, minute=59, second=59, microsecond=999999)
    week_start = (now_kst - timedelta(days=6)).replace(hour=0, minute=0, second=0, microsecond=0)
    
    response = supabase.table('alih_schedule') \
        .select('id, game_no, match_at, home_alih_team_id, away_alih_team_id, home_alih_team_score, away_alih_team_score') \
        .gte('match_at', week_start.isoformat()) \
        .lte('match_at', today_end.isoformat()) \
        .order('match_at') \
        .execute()
    
    return [m for m in response.data if m.get('home_alih_team_score') is not None]


def get_upcoming_series() -> list:
    """ë‹¤ìŒ ì£¼ ì˜ˆì •ëœ ê²½ê¸° ì¡°íšŒ (Previewìš©)"""
    now_kst = datetime.utcnow() + timedelta(hours=9)
    
    days_until_friday = (4 - now_kst.weekday()) % 7
    if days_until_friday == 0:
        days_until_friday = 1
    
    next_friday = now_kst + timedelta(days=days_until_friday)
    series_start = next_friday.replace(hour=0, minute=0, second=0, microsecond=0)
    series_end = (series_start + timedelta(days=9)).replace(hour=23, minute=59, second=59, microsecond=999999)
    
    response = supabase.table('alih_schedule') \
        .select('id, game_no, match_at, home_alih_team_id, away_alih_team_id') \
        .gte('match_at', series_start.isoformat()) \
        .lte('match_at', series_end.isoformat()) \
        .order('match_at') \
        .execute()
    
    return response.data


# =============================================================================
# 2. í—¬í¼ í•¨ìˆ˜
# =============================================================================

def get_jp_team_name(team_info: dict, team_id: int) -> str:
    """íŒ€ ì¼ë³¸ì–´ ì´ë¦„ ë°˜í™˜"""
    team = team_info.get(team_id, {})
    return team.get('japanese_name') or team.get('english_name', 'Unknown')


def format_standings_jp(team_info: dict, standings: dict) -> str:
    """ìˆœìœ„í‘œ í¬ë§·"""
    sorted_standings = sorted(standings.values(), key=lambda x: x.get('rank', 99))
    lines = []
    for s in sorted_standings:
        team_id = s['team_id']
        name = get_jp_team_name(team_info, team_id)
        rank = s.get('rank', '?')
        points = s.get('points', 0)
        lines.append(f"{rank}ä½ {name} ({points}pts)")
    return "\n".join(lines)


def generate_base_hashtags() -> str:
    """ê¸°ë³¸ í•´ì‹œíƒœê·¸"""
    return "#ã‚¢ã‚¸ã‚¢ãƒªãƒ¼ã‚° #ALIH #ã‚¢ã‚¤ã‚¹ãƒ›ãƒƒã‚±ãƒ¼"


# =============================================================================
# 3. ìŠ¤ë ˆë“œ ì»¨í…ì¸  ìƒì„± (Groq AI)
# =============================================================================

def generate_review_thread(matches: list, team_info: dict, standings: dict) -> list[str]:
    """
    Series Review ìŠ¤ë ˆë“œ ìƒì„±
    Returns: [ì²« íŠ¸ìœ—, ë¦¬í”Œë¼ì´1, ë¦¬í”Œë¼ì´2, ...]
    """
    if not GROQ_API_KEY:
        print("âš ï¸ GROQ_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ.")
        return []
    
    client = Groq(api_key=GROQ_API_KEY)
    
    now_kst = datetime.utcnow() + timedelta(hours=9)
    week_start = now_kst - timedelta(days=6)
    date_range = f"{week_start.strftime('%m/%d')}ã€œ{now_kst.strftime('%m/%d')}"
    
    # ê²½ê¸° ì •ë³´ ì¤€ë¹„
    match_details = []
    for match in matches:
        home_name = get_jp_team_name(team_info, match['home_alih_team_id'])
        away_name = get_jp_team_name(team_info, match['away_alih_team_id'])
        home_score = match.get('home_alih_team_score', 0)
        away_score = match.get('away_alih_team_score', 0)
        game_no = match['game_no']
        match_dt = datetime.fromisoformat(match['match_at'].replace('Z', '+00:00')) + timedelta(hours=9)
        date_str = match_dt.strftime('%m/%d')
        
        match_details.append({
            'date': date_str,
            'home': home_name,
            'away': away_name,
            'home_score': home_score,
            'away_score': away_score,
            'game_no': game_no,
            'link': f"https://alhockey.fans/schedule/{game_no}?lang=jp"
        })
    
    standings_text = format_standings_jp(team_info, standings)
    
    # íŒ€ ì •ë³´ ì»¨í…ìŠ¤íŠ¸
    team_context = "\n".join([
        f"- {t.get('japanese_name', t.get('english_name'))}"
        for t in team_info.values() if t.get('japanese_name') or t.get('english_name')
    ])
    
    prompt = f"""ã‚ãªãŸã¯ã‚¢ã‚¸ã‚¢ãƒªãƒ¼ã‚°ã‚¢ã‚¤ã‚¹ãƒ›ãƒƒã‚±ãƒ¼ã®X(@alhockey_fans)é‹å–¶è€…ã§ã™ã€‚
ä»Šé€±ã®è©¦åˆçµæœã‚’X(Twitter)ã®ã‚¹ãƒ¬ãƒƒãƒ‰å½¢å¼ã§æŠ•ç¨¿ã—ã¾ã™ã€‚

ã€é‡è¦ã€‘å„ãƒ„ã‚¤ãƒ¼ãƒˆã¯å¿…ãš280æ–‡å­—ä»¥å†…ã«ã—ã¦ãã ã•ã„ã€‚

## ã‚¹ãƒ¬ãƒƒãƒ‰æ§‹æˆ
1. **ãƒ¡ã‚¤ãƒ³ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆ1ã¤ç›®ï¼‰**: ä»Šé€±ã®ç·æ‹¬è¦ç´„ + ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°
2. **ãƒªãƒ—ãƒ©ã‚¤ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆ2ã¤ç›®ä»¥é™ï¼‰**: å„è©¦åˆã”ã¨ã«1ãƒ„ã‚¤ãƒ¼ãƒˆ

## ãƒãƒ¼ãƒ æƒ…å ±
{team_context}

## ä»Šé€±ã®è©¦åˆçµæœ ({date_range})
"""
    
    # ê° ê²½ê¸°ë³„ ìƒì„¸ ì •ë³´ (ë§í¬ í¬í•¨)
    for i, m in enumerate(match_details, 1):
        prompt += f"\n{i}. {m['date']} {m['home']} {m['home_score']}-{m['away_score']} {m['away']}"
        prompt += f"\n   ë§í¬: {m['link']}"
    
    prompt += f"""

## ç¾åœ¨ã®é †ä½
{standings_text}

## å‡ºåŠ›å½¢å¼ï¼ˆJSONã§å‡ºåŠ›ï¼‰
ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
{{
  "main_tweet": "ãƒ¡ã‚¤ãƒ³ãƒ„ã‚¤ãƒ¼ãƒˆã®å†…å®¹ï¼ˆ280æ–‡å­—ä»¥å†…ã€ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°å«ã‚€ï¼‰",
  "reply_tweets": [
    "1è©¦åˆç›®ã®ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆ280æ–‡å­—ä»¥å†…ï¼‰",
    "2è©¦åˆç›®ã®ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆ280æ–‡å­—ä»¥å†…ï¼‰",
    ...
  ]
}}

## ãƒ¡ã‚¤ãƒ³ãƒ„ã‚¤ãƒ¼ãƒˆã®è¦ä»¶
- ä»Šé€±ã®çµæœã®ç°¡æ½”ãªç·æ‹¬ï¼ˆä¾‹ï¼šã€Œæ¿€æˆ¦ã®1é€±é–“ï¼é¦–ä½ãƒ¬ãƒƒãƒ‰ã‚¤ãƒ¼ã‚°ãƒ«ã‚¹ãŒ2é€£å‹ğŸ”¥ã€ï¼‰
- çµµæ–‡å­—ä½¿ç”¨ï¼ˆğŸ’â„ï¸ğŸ”¥ãªã©ï¼‰
- æœ€å¾Œã« #ã‚¢ã‚¸ã‚¢ãƒªãƒ¼ã‚° #ALIH #ã‚¢ã‚¤ã‚¹ãƒ›ãƒƒã‚±ãƒ¼
- 280æ–‡å­—ä»¥å†…

## ãƒªãƒ—ãƒ©ã‚¤ãƒ„ã‚¤ãƒ¼ãƒˆã®è¦ä»¶ï¼ˆå„è©¦åˆã”ã¨ï¼‰
- è©¦åˆæ—¥æ™‚ã¨å¯¾æˆ¦ã‚«ãƒ¼ãƒ‰
- ã‚¹ã‚³ã‚¢ã¨ç°¡å˜ãªä¸€è¨€ã‚³ãƒ¡ãƒ³ãƒˆ
- ã€é‡è¦ã€‘å„è©¦åˆã®ãƒªãƒ³ã‚¯ã¯ä¸Šè¨˜ã®ã€Œãƒªãƒ³ã‚¯ã€ã‚’ãã®ã¾ã¾ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚çµ¶å¯¾ã«å¤‰æ›´ã—ãªã„ã§ãã ã•ã„ã€‚
- 280æ–‡å­—ä»¥å†…
- çµµæ–‡å­—ä½¿ç”¨

å¿…ãšJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""

    print(f"\n{'='*60}")
    print(f"ğŸ“¤ [Groq API] Series Review ã‚¹ãƒ¬ãƒƒãƒ‰ç”Ÿæˆ")
    print(f"{'='*60}")
    
    try:
        completion = client.chat.completions.create(
            model="openai/gpt-oss-120b",
            messages=[{"role": "user", "content": prompt}]
        )
        response_text = completion.choices[0].message.content
        
        # JSON íŒŒì‹± ì‹œë„
        import json
        # JSON ë¸”ë¡ ì¶”ì¶œ
        json_match = re.search(r'\{[\s\S]*\}', response_text)
        if json_match:
            data = json.loads(json_match.group())
            tweets = [data.get('main_tweet', '')]
            tweets.extend(data.get('reply_tweets', []))
            return tweets
        else:
            print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ë°˜í™˜")
            return [response_text]
            
    except Exception as e:
        print(f"âŒ Groq API ã‚¨ãƒ©ãƒ¼: {e}")
        return []


def generate_preview_thread(matches: list, team_info: dict, standings: dict) -> list[str]:
    """
    Series Preview ìŠ¤ë ˆë“œ ìƒì„±
    Returns: [ì²« íŠ¸ìœ—, ë¦¬í”Œë¼ì´1, ë¦¬í”Œë¼ì´2, ...]
    """
    if not GROQ_API_KEY:
        print("âš ï¸ GROQ_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ.")
        return []
    
    client = Groq(api_key=GROQ_API_KEY)
    
    # ë‚ ì§œ ë²”ìœ„
    if matches:
        first_match = datetime.fromisoformat(matches[0]['match_at'].replace('Z', '+00:00')) + timedelta(hours=9)
        last_match = datetime.fromisoformat(matches[-1]['match_at'].replace('Z', '+00:00')) + timedelta(hours=9)
        date_range = f"{first_match.strftime('%m/%d')}ã€œ{last_match.strftime('%m/%d')}"
    else:
        now_kst = datetime.utcnow() + timedelta(hours=9)
        date_range = f"{(now_kst + timedelta(days=1)).strftime('%m/%d')}ã€œ"
    
    # ê²½ê¸° ì •ë³´ ì¤€ë¹„
    match_details = []
    for match in matches:
        home_name = get_jp_team_name(team_info, match['home_alih_team_id'])
        away_name = get_jp_team_name(team_info, match['away_alih_team_id'])
        game_no = match['game_no']
        match_dt = datetime.fromisoformat(match['match_at'].replace('Z', '+00:00')) + timedelta(hours=9)
        datetime_str = match_dt.strftime('%m/%d %H:%M')
        
        # ìˆœìœ„ ì •ë³´
        home_rank = standings.get(match['home_alih_team_id'], {}).get('rank', '?')
        away_rank = standings.get(match['away_alih_team_id'], {}).get('rank', '?')
        
        match_details.append({
            'datetime': datetime_str,
            'home': home_name,
            'away': away_name,
            'home_rank': home_rank,
            'away_rank': away_rank,
            'game_no': game_no,
            'link': f"https://alhockey.fans/schedule/{game_no}?lang=jp"
        })
    
    standings_text = format_standings_jp(team_info, standings)
    
    # íŒ€ ì •ë³´ ì»¨í…ìŠ¤íŠ¸
    team_context = "\n".join([
        f"- {t.get('japanese_name', t.get('english_name'))}"
        for t in team_info.values() if t.get('japanese_name') or t.get('english_name')
    ])
    
    prompt = f"""ã‚ãªãŸã¯ã‚¢ã‚¸ã‚¢ãƒªãƒ¼ã‚°ã‚¢ã‚¤ã‚¹ãƒ›ãƒƒã‚±ãƒ¼ã®X(@alhockey_fans)é‹å–¶è€…ã§ã™ã€‚
æ¥é€±ã®è©¦åˆäºˆå®šã‚’X(Twitter)ã®ã‚¹ãƒ¬ãƒƒãƒ‰å½¢å¼ã§æŠ•ç¨¿ã—ã¾ã™ã€‚

ã€é‡è¦ã€‘å„ãƒ„ã‚¤ãƒ¼ãƒˆã¯å¿…ãš280æ–‡å­—ä»¥å†…ã«ã—ã¦ãã ã•ã„ã€‚

## ã‚¹ãƒ¬ãƒƒãƒ‰æ§‹æˆ
1. **ãƒ¡ã‚¤ãƒ³ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆ1ã¤ç›®ï¼‰**: æ¥é€±ã®è¦‹ã©ã“ã‚ç·æ‹¬ + ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°
2. **ãƒªãƒ—ãƒ©ã‚¤ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆ2ã¤ç›®ä»¥é™ï¼‰**: å„è©¦åˆã”ã¨ã«1ãƒ„ã‚¤ãƒ¼ãƒˆ

## ãƒãƒ¼ãƒ æƒ…å ±
{team_context}

## æ¥é€±ã®è©¦åˆäºˆå®š ({date_range})
"""
    
    # ê° ê²½ê¸°ë³„ ìƒì„¸ ì •ë³´ (ë§í¬ í¬í•¨)
    for i, m in enumerate(match_details, 1):
        prompt += f"\n{i}. {m['datetime']} {m['home']}({m['home_rank']}ä½) vs {m['away']}({m['away_rank']}ä½)"
        prompt += f"\n   ë§í¬: {m['link']}"
    
    prompt += f"""

## ç¾åœ¨ã®é †ä½
{standings_text}

## å‡ºåŠ›å½¢å¼ï¼ˆJSONã§å‡ºåŠ›ï¼‰
ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
{{
  "main_tweet": "ãƒ¡ã‚¤ãƒ³ãƒ„ã‚¤ãƒ¼ãƒˆã®å†…å®¹ï¼ˆ280æ–‡å­—ä»¥å†…ã€ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°å«ã‚€ï¼‰",
  "reply_tweets": [
    "1è©¦åˆç›®ã®ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆ280æ–‡å­—ä»¥å†…ï¼‰",
    "2è©¦åˆç›®ã®ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆ280æ–‡å­—ä»¥å†…ï¼‰",
    ...
  ]
}}

## ãƒ¡ã‚¤ãƒ³ãƒ„ã‚¤ãƒ¼ãƒˆã®è¦ä»¶
- æ¥é€±ã®è¦‹ã©ã“ã‚ã®ç°¡æ½”ãªç·æ‹¬ï¼ˆä¾‹ï¼šã€Œæ¥é€±ã¯é¦–ä½æ±ºæˆ¦ï¼è¦‹é€ƒã›ãªã„ç†±ã„1é€±é–“ğŸ”¥ã€ï¼‰
- çµµæ–‡å­—ä½¿ç”¨ï¼ˆğŸ’âš”ï¸ğŸ”¥ğŸ“…ãªã©ï¼‰
- æœ€å¾Œã« #ã‚¢ã‚¸ã‚¢ãƒªãƒ¼ã‚° #ALIH #ã‚¢ã‚¤ã‚¹ãƒ›ãƒƒã‚±ãƒ¼
- 280æ–‡å­—ä»¥å†…

## ãƒªãƒ—ãƒ©ã‚¤ãƒ„ã‚¤ãƒ¼ãƒˆã®è¦ä»¶ï¼ˆå„è©¦åˆã”ã¨ï¼‰
- è©¦åˆæ—¥æ™‚ã¨å¯¾æˆ¦ã‚«ãƒ¼ãƒ‰ï¼ˆé †ä½å«ã‚€ï¼‰
- è¦‹ã©ã“ã‚ã‚„æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆã‚’ä¸€è¨€ã§
- ã€é‡è¦ã€‘å„è©¦åˆã®ãƒªãƒ³ã‚¯ã¯ä¸Šè¨˜ã®ã€Œãƒªãƒ³ã‚¯ã€ã‚’ãã®ã¾ã¾ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚çµ¶å¯¾ã«å¤‰æ›´ã—ãªã„ã§ãã ã•ã„ã€‚
- 280æ–‡å­—ä»¥å†…
- çµµæ–‡å­—ä½¿ç”¨
- é¸æ‰‹åã¯ä½¿ç”¨ã—ãªã„ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ï¼‰

å¿…ãšJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""

    print(f"\n{'='*60}")
    print(f"ğŸ“¤ [Groq API] Series Preview ã‚¹ãƒ¬ãƒƒãƒ‰ç”Ÿæˆ")
    print(f"{'='*60}")
    
    try:
        completion = client.chat.completions.create(
            model="openai/gpt-oss-120b",
            messages=[{"role": "user", "content": prompt}]
        )
        response_text = completion.choices[0].message.content
        
        # JSON íŒŒì‹± ì‹œë„
        import json
        json_match = re.search(r'\{[\s\S]*\}', response_text)
        if json_match:
            data = json.loads(json_match.group())
            tweets = [data.get('main_tweet', '')]
            tweets.extend(data.get('reply_tweets', []))
            return tweets
        else:
            print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ë°˜í™˜")
            return [response_text]
            
    except Exception as e:
        print(f"âŒ Groq API ã‚¨ãƒ©ãƒ¼: {e}")
        return []


# =============================================================================
# 4. Slack ì „ì†¡
# =============================================================================

def clean_markdown(text: str) -> str:
    """ë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ì œê±°"""
    text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)
    text = re.sub(r'__(.+?)__', r'\1', text)
    text = re.sub(r'\*(.+?)\*', r'\1', text)
    text = re.sub(r'_(.+?)_', r'\1', text)
    return text


def send_thread_to_slack(tweets: list[str], content_type: str):
    """Slack Webhookìœ¼ë¡œ ìŠ¤ë ˆë“œ í˜•ì‹ ì»¨í…ì¸  ì „ì†¡"""
    if not tweets:
        print("âš ï¸ ì „ì†¡í•  íŠ¸ìœ—ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    emoji = "ğŸ“Š" if content_type == "review" else "ğŸ”®"
    title = "Series Review" if content_type == "review" else "Series Preview"
    
    # ê° íŠ¸ìœ— ê¸€ììˆ˜ ì²´í¬
    for i, tweet in enumerate(tweets):
        char_count = len(tweet)
        status = "âœ…" if char_count <= X_CHAR_LIMIT else "âš ï¸ ì´ˆê³¼!"
        print(f"  Tweet {i+1}: {char_count}ì {status}")
    
    if not SLACK_WEBHOOK_URL:
        print("âš ï¸ SLACK_WEBHOOK_URL ë¯¸ì„¤ì •. Slack ì „ì†¡ ìƒëµ.")
        print("\n" + "="*60)
        print("ğŸ“ ìƒì„±ëœ ìŠ¤ë ˆë“œ:")
        print("="*60)
        for i, tweet in enumerate(tweets):
            label = "ğŸ§µ ë©”ì¸" if i == 0 else f"â†ªï¸ ë¦¬í”Œë¼ì´ {i}"
            print(f"\n{label} ({len(tweet)}ì):")
            print(tweet)
        return
    
    # Slack ë¸”ë¡ êµ¬ì„±
    blocks = [
        {
            "type": "header",
            "text": {"type": "plain_text", "text": f"{emoji} X Thread: {title}", "emoji": True}
        },
        {
            "type": "context",
            "elements": [
                {"type": "mrkdwn", "text": f"ğŸ§µ ìŠ¤ë ˆë“œ í˜•ì‹: ë©”ì¸ 1ê°œ + ë¦¬í”Œë¼ì´ {len(tweets)-1}ê°œ"}
            ]
        },
        {"type": "divider"}
    ]
    
    # ê° íŠ¸ìœ— ì¶”ê°€
    for i, tweet in enumerate(tweets):
        clean_tweet = clean_markdown(tweet)
        char_count = len(clean_tweet)
        char_status = "âœ…" if char_count <= X_CHAR_LIMIT else "âš ï¸ì´ˆê³¼"
        
        label = "ğŸ§µ **ë©”ì¸ íŠ¸ìœ—**" if i == 0 else f"â†ªï¸ **ë¦¬í”Œë¼ì´ {i}**"
        
        blocks.append({
            "type": "section",
            "text": {"type": "mrkdwn", "text": f"{label} ({char_count}ì {char_status})\n```{clean_tweet}```"}
        })
    
    blocks.append({"type": "divider"})
    blocks.append({
        "type": "context",
        "elements": [
            {"type": "mrkdwn", "text": "ğŸ“‹ ìœ„ ìˆœì„œëŒ€ë¡œ @alhockey_fans ì—ì„œ ìŠ¤ë ˆë“œë¡œ ê²Œì‹œí•˜ì„¸ìš”"}
        ]
    })
    
    payload = {"blocks": blocks}
    
    try:
        response = requests.post(SLACK_WEBHOOK_URL, json=payload)
        if response.status_code == 200:
            print(f"âœ… Slack ìŠ¤ë ˆë“œ ì „ì†¡ ì™„ë£Œ ({content_type})")
        else:
            print(f"âŒ Slack ì „ì†¡ ì‹¤íŒ¨: {response.status_code} - {response.text}")
    except Exception as e:
        print(f"âŒ Slack ì „ì†¡ ì—ëŸ¬: {e}")


# =============================================================================
# 5. ë©”ì¸ í•¨ìˆ˜
# =============================================================================

def main():
    if len(sys.argv) < 2:
        print("Usage: python x_content.py <review|preview>")
        print("  review  - ì§€ë‚œ ì£¼ ê²½ê¸° ê²°ê³¼ ìš”ì•½ (ì¼ìš”ì¼ ë°œí–‰)")
        print("  preview - ë‹¤ìŒ ì£¼ ê²½ê¸° ì˜ˆê³  (ëª©ìš”ì¼ ë°œí–‰)")
        sys.exit(1)
    
    content_type = sys.argv[1].lower()
    if content_type not in ['review', 'preview']:
        print(f"âŒ ì˜ëª»ëœ content_type: {content_type}")
        sys.exit(1)
    
    print(f"[{datetime.now().isoformat()}] ğŸš€ X Thread Generator ì‹œì‘ ({content_type})")
    print(f"ğŸ“ X ê¸€ììˆ˜ ì œí•œ: {X_CHAR_LIMIT}ì")
    
    # Supabase ì´ˆê¸°í™”
    init_supabase()
    
    # íŒ€ ì •ë³´ & ìˆœìœ„ ì •ë³´ ë¡œë“œ
    team_info = get_team_info()
    standings = get_standings_info()
    print(f"ğŸ“Š íŒ€ ì •ë³´ ë¡œë“œ: {len(team_info)}ê°œ íŒ€")
    
    # ìŠ¤ë ˆë“œ ìƒì„±
    if content_type == 'review':
        matches = get_weekly_results()
        print(f"ğŸ“… ì§€ë‚œ ì£¼ ê²½ê¸°: {len(matches)}ê°œ")
        
        if not matches:
            print("âš ï¸ ì§€ë‚œ ì£¼ ê²½ê¸° ì—†ìŒ. ì¢…ë£Œ.")
            return
        
        tweets = generate_review_thread(matches, team_info, standings)
        
    else:  # preview
        matches = get_upcoming_series()
        print(f"ğŸ“… ë‹¤ìŒ ì£¼ ê²½ê¸°: {len(matches)}ê°œ")
        
        if not matches:
            print("âš ï¸ ë‹¤ìŒ ì£¼ ê²½ê¸° ì—†ìŒ. ì¢…ë£Œ.")
            return
        
        tweets = generate_preview_thread(matches, team_info, standings)
    
    if tweets:
        print(f"\nğŸ§µ ìƒì„±ëœ ìŠ¤ë ˆë“œ: {len(tweets)}ê°œ íŠ¸ìœ—")
        send_thread_to_slack(tweets, content_type)
    else:
        print("âŒ ìŠ¤ë ˆë“œ ìƒì„± ì‹¤íŒ¨")
    
    print(f"\n[{datetime.now().isoformat()}] âœ… ì™„ë£Œ")


if __name__ == "__main__":
    main()
